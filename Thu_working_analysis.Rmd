---
title: "Preliminary ELSA Machine Learnings Tests"
author: "Jonathan Seiden, Thu Pham"
date: "8/08/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readstata13)
library(tidyverse)
library(glmnet)
library(caret)
library(fastDummies)
```

# Data consolidation process  

In this section, we process the data to get it into a format where each row is a child. 

## Child and Teacher Observation  
First we input the child and teacher observations and process them.

For each child in the COP data, we calculate:

1) The average for the child for each of the indicators across sweeps
2) The class average for each indicator *omitting* the child her/himself
3) The class standard deviation for each indicator *omitting* the child her/himself (only including children with 10 or more sweeps)

We then calculate the class average of the TOP indicators for the adults in the class by averaging across sweeps, and merge this data (one to many) with the child-level data. This merged data set contains XXX children in XXX classes

```{r y1_obs, warning=FALSE}
#Input the Year One long child and teacher observation data 
y1_child_obs_raw <- read.dta13("y1o_c_long.dta")
y1_teacher_obs_raw <- read.dta13("y1o_t_long.dta")
y1_coverpage_obs <- read.dta13("y1o_coverpage.dta")

#Re-format the child data so that it is one row per child

y1_child_obs <- y1_child_obs_raw %>%
  mutate(cid = ifelse(childid == "N/A", o_c_uniqueid, childid)) %>%
  group_by(cid, classid) %>%
  mutate(nsweeps = n()) %>%
  mutate_at(vars(o_c_verbal:o_c_focus), as.character) %>% 
  select(c(classid, nsweeps, o_c_verbal:o_c_focus)) %>%
  dummy_cols(select_columns = c("o_c_verbal", "o_c_towhom", "o_c_schedule", "o_c_interaction", "o_c_typetask", "o_c_involvement", "o_c_focus"),
             remove_selected_columns = TRUE) %>% 
  group_by(classid, cid) %>%
  # replaced everything() with nsweeps:last_col()
  summarize(across(nsweeps:last_col(), ~ mean(.x, na.rm = TRUE))) %>%
  filter(nsweeps >= 10 ) %>% #THIS IS AN ARBITRARY PARAMETER
  group_by(classid) %>%
  mutate(nclass = n()) %>%
  # what to do when there is only one student in the class?? will need to subtract one
  mutate(across(starts_with("o_c"), ~ ((sum(.x, na.rm = TRUE) - .x) / get('nclass')),
    .names = "{col}_classmean")) %>%
  mutate(across(starts_with("o_c") & !ends_with("classmean"), ~ sqrt((sum(.x - get(str_c(cur_column(), '_classmean')), na.rm = TRUE)^2 - (.x - get(str_c(cur_column(),'_classmean')))^2) / get('nclass')), 
                .names = "{col}_class_sd")) %>%
  ungroup

#Re-format the teacher data so that it is one row per class
y1_teacher_obs <- y1_teacher_obs_raw %>% 
  dummy_cols(select_columns = c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o"),
             remove_selected_columns = TRUE) %>% 
    group_by(classid) %>%
  summarize(
    nsweeps = n(),
    nadult = length(unique(o_t_uniqueid)),
    across(starts_with(c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o")),
           ~ mean(.x, na.rm = TRUE))) %>%
  select(-ends_with("_")) %>% 
  ungroup

#Merge teacher and child observations 
y1_obs <- left_join(y1_child_obs, y1_teacher_obs, by = "classid")

```
```{r}
table(y1_teacher_obs$nadult)
```


```{r y2_obs, warning=FALSE}
#Input the Year One long child and teacher observation data 
y2_child_obs_raw <- read.dta13("y2o_c_long.dta")
y2_teacher_obs_raw <- read.dta13("y2o_t_long.dta")
y2_coverpage_obs <- read.dta13("y2o_coverpage.dta")

mean(y2_coverpage_obs$classid %in% y1_coverpage_obs$classid)

#Re-format the child data so that it is one row per child
y2_child_obs <- y2_child_obs_raw %>%
  group_by(cid, classid) %>%
  mutate(nsweeps = n()) %>%
  mutate_at(vars(o_c_verbal:o_c_focus), as.character) %>% 
  select(c(classid, nsweeps, o_c_verbal:o_c_focus)) %>%
  dummy_cols(select_columns = c("o_c_verbal", "o_c_towhom", "o_c_schedule", "o_c_interaction", "o_c_typetask", "o_c_involvement", "o_c_focus"),
             remove_selected_columns = TRUE) %>% 
  group_by(cid, classid) %>%
  summarize(across(everything(),  ~ mean(.x, na.rm = TRUE))) %>%
  filter(nsweeps >= 10 ) %>% #THIS IS AN ARBITRARY PARAMETER
  group_by(classid) %>%
  mutate(nclass = n()) %>%
  # changed this so that the leave-out mean is not hard coded (also so that there 
  # are no longer NaNs in the class mean)
  mutate(across(starts_with("o_c"), ~ ((sum(.x, na.rm = TRUE) - .x) / (n() - 1)),
    .names = "{col}_classmean")) %>%
  ungroup

#Re-format the teacher data so that it is one row per class
y2_teacher_obs <- y2_teacher_obs_raw %>% 
  dummy_cols(select_columns = c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o"),
             remove_selected_columns = TRUE) %>% 
    group_by(classid) %>%
  summarize(
    nsweeps = n(),
    nadult = length(unique(o_t_uniqueid)),
    across(starts_with(c("o_t_verbal_o", "o_t_whom_o", "o_t_schedule_o", 
                                "o_t_task_o", "o_t_instruct", "o_t_focus_o", 
                                "o_t_tone_o", "o_t_attention_o", "o_t_es_o")),
            ~ mean(.x, na.rm = TRUE))) %>%
  select(-ends_with("_")) %>% 
  ungroup

#Extract the caretype from the observation sheet
## ASK -- what is meant by this?

#Merge teacher and child observations 
y2_obs <- left_join(y2_child_obs, y2_teacher_obs, by = "classid")

```


Below we now input the child-level outcome data. We focus on the outcomes that Emily suggested, and extract the year 1 and year 2 values for each child and then merge to create a single dataset. 

```{r child.outcomes, warning=FALSE}
#Get Year 1 and Year 2 child data
y1_child_outcomes_raw <- read.dta13("y1c.dta")
y2_child_outcomes_raw <- read.dta13("y2c.dta")

#Rename all y1 variables and y2 variables so we don't lose them when merging
y1_child_outcomes <-  y1_child_outcomes_raw %>% 
  select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pra_total, c_pbsa_total, c_quils_total_raw, c_wjlw_str, c_wjap_str) %>% 
  rename_all( ~ paste0("y1_", .x)) %>% 
  mutate(cid = as.character(y1_cid))

y2_child_outcomes <-  y2_child_outcomes_raw %>% 
  select(cid, c_mefs_str, c_pt_pcorrect, c_ltr_cogsoc_comp, c_ltr_emo_comp, 
         c_pbsa_allgrades_total, c_pra_allgrades_total, c_quils_total_raw, 
         c_wjlw_str, c_wjap_str, c_age_cat_test, c_age_test) %>% 
  rename(c_pra_total = c_pra_allgrades_total,
         c_pbsa_total = c_pbsa_allgrades_total) %>% 
  rename_all( ~ paste0("y2_", .x)) %>% 
  mutate(cid = as.character(y2_cid))

#Merge Y2 and Y1 data together and calculate the gain score for each of the outcomes
child_outcomes <- merge(y1_child_outcomes, y2_child_outcomes, by = "cid") %>% 
  mutate(gain_c_mefs_str = y2_c_mefs_str - y1_c_mefs_str, 
         gain_c_pt_pcorrect = y2_c_pt_pcorrect - y1_c_pt_pcorrect,  
         gain_c_ltr_cogsoc_comp = y2_c_ltr_cogsoc_comp - y1_c_ltr_cogsoc_comp,  
         gain_c_ltr_emo_comp = y2_c_ltr_emo_comp - y1_c_ltr_emo_comp, 
         gain_c_pra_total = y2_c_pra_total - y1_c_pra_total, 
         gain_c_pbsa_total = y2_c_pbsa_total - y1_c_pbsa_total, 
         gain_c_quils_total_raw = y2_c_quils_total_raw - y1_c_quils_total_raw, 
         gain_c_wjlw_str = y2_c_wjlw_str - y1_c_wjlw_str, 
         gain_c_wjap_str = y2_c_wjap_str - y1_c_wjap_str,
         cid = as.numeric(cid))

```

Finally, we merge together the Year 1 observation data with the Year 1 & 2 child outcome data and add in care type. We omit observations that have no classroom observation resulting in a total analytic dataframe of 1169 observations of 64 variables. 

```{r merge.obs.outcomes y1 p1}
#Merge in the outcomes data 

# CHANGES THIS TO y1_obs (I think this is what was intended)

# what to do with NAs here? I'm going to replace with zeros for the time being

# add this line in so that the merge is correctly executed

y1_obs <- y1_obs %>%
  filter(!is.na(cid)) %>%
  mutate(cid = as.numeric(cid))

outcomes_and_obs_y1 <- left_join(child_outcomes, y1_obs, by = "cid") %>% 
  mutate(cid = as.character(cid))

#Add in the care type
caretype <- read.dta13("y1caretype.dta") %>% 
  mutate(cid = as.character(cid))

#Remove observations that have no care type or no classroom observation
outcomes_and_obs_full_y1 <- left_join(outcomes_and_obs_y1, caretype, by = "cid") %>% 
  mutate(hasobservation = is.na(classid)) %>% 
  filter(!is.na(caretype)) %>%
  filter(!is.na(classid))

# outcomes_and_obs_full_y1 <- outcomes_and_obs %>% 
#   filter(!is.na(classid))

#Remove Y1 and Y2 data for cleanliness
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  select(-starts_with(c("y1", "y2")))

#Remove some irrelevant variables
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  select(-c(famid, dob:dob_uncertain, actual_fcc:hasobservation)) %>% 
  mutate(caretype = as.factor(caretype),
         actualtype = as.factor(actualtype))
```

```{r}
# replaces missing data with mean (if numeric) and mode (if factor)

getmode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

replace.na <- function(var){
  ifelse(is.na(var) | is.nan(var), 
         ifelse(is.factor(var), getmode(var), mean(var)), var)
}
```



```{r merge.obs.outcomes y1 p2}
# names(outcomes_and_obs_full_y1)
outcomes_and_obs_full_y1 <- outcomes_and_obs_full_y1 %>% 
  mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)

# what is o_t_sched_t supposed to be for? replacing with actualtype for now just to run analysis

# replacing all NaNs in hopes that it will fix the model matrix issue
# originally was o_c_verbal_talk:o_t_sched_t

dim(outcomes_and_obs_full_y1)
```

## Analysis

We will first try a cross-validated LASSO, which will aggressively remove variables that do little to improve the predictive accuracy of the model.  

```{r loop lasso year1, echo=TRUE, fig.height=8}
# looping through gain variables

# initiate two lists to store results of each model (for the graph and the coefficients)

# https://stackoverflow.com/questions/9332417/whats-a-good-way-to-store-multiple-models-in-an-r-data-structure
set.seed(4224)

gain_ind <- which(startsWith(colnames(outcomes_and_obs_full_y1), "gain"))

models_y1 <- list()
coefs_y1 <- list()

for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y1)[i]
  df_analysis <- outcomes_and_obs_full_y1 %>%
    filter(!is.na(outcomes_and_obs_full_y1[[name]])) %>%
    select(c(name, "o_c_verbal_Fuss/Cry (FC)":actualtype))
  print(name)
  # double check that this is okay
  options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  y = df_analysis[[name]]
  print(dim(x))
  x = x[, -1]
  

  # call cv.glmnet()
  model_lasso <- cv.glmnet(x = x, y = y, alpha = 1)
  plot(model_lasso)
  
  models_y1[[name]] <- model_lasso
  
  cc = coef(model_lasso, s = model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  cc = cc[cc[,1]!=0,1]
  coefs_y1[[name]] <- cc
  print(cc)

}

```

```{r y1 pulling most predictive covariates}
# loop through the names associated with each outcome -- add 1 to corresponding entry
count_coefs_y1 <- list()
for (outcome in coefs_y1) {
  for (name in names(outcome)) {
    if (name == '(Intercept)') {
      next
    }
    count_coefs_y1[[name]] <- ifelse(is.null(count_coefs_y1[[name]]), 1, 
                                     count_coefs_y1[[name]] + 1)
  }
}
```



```{r loop rf_test year1, echo=TRUE, fig.height=8}

# make sure this works with small subset of data
for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y1)[i]
  df_analysis <- outcomes_and_obs_full_y1 %>%
    filter(!is.na(outcomes_and_obs_full_y1[[name]])) %>%
    select(c(name, "o_c_verbal_Fuss/Cry (FC)":actualtype)) 
    # ask about verbal_fuss vs o_c_verbal_Talk(T) (original)
    # mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)
  print(name)
  # options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  # Fit the random forest model
  rf_fit <- train(as.formula(paste(name, "~ .")), #Use all variables in the prediction
                data = df_analysis, #Use the training data
                method = "ranger",
                importance = "permutation",
                ntree = 5,
                na.action=na.pass)
                
  varImp(rf_fit) %>%
    pluck(1) %>%
    rownames_to_column("var") %>%
    ggplot(aes(x = reorder(var, Overall), y = Overall)) +
    geom_col(fill = "grey75") +
    coord_flip() +
    theme_minimal()
}


# commented out this code because it has been used earlier

# rf_fit <- train(gain_c_pt_pcorrect ~ ., 
#                 data = gain_c_pt_pcorrect_analysis) #Use all variables in the prediction
# rf_fit <- train(gain_c_pt_pcorrect ~ .) #Use all variables in the prediction
# table(outcomes_and_obs_full_y1$nclass)
```




```{r next steps}
#NOTES FROM MEETINGI 8/8
#1. Try Y2 observation data instead of Y1, and compare results
#2. Try a model with a bunch of predictors from Y1 Y2 -- looking at more demographic variables
# wait for Jonathan to see which demographic variables are important
#3. Use the particular caretype from the  setting that is being observed in. (prov_type)
#Collapse CC-Community Based & CC- License Exempt -- 
#4. Include leave-out standard deviation for each predictor as well
#5. Incorporte child-level covariates -- wait for this one as well
#6. Age and elapsed time for assessment 
# look for date in the cleaning process -- flag it and let Jonathan take closer look

## 4 is a priority, plus other things we discussed (on google doc)
```


```{r merge.obs.outcomes y2 p1}
#Merge in the outcomes data 
#  Try Y2 observation data instead of y1, and compare results

# add this line in so that the merge is correctly executed

y2_obs <- y2_obs %>%
  filter(!is.na(cid)) %>%
  mutate(cid = as.numeric(cid))

outcomes_and_obs_y2 <- left_join(child_outcomes, y2_obs, by = "cid") %>% 
  mutate(cid = as.character(cid))

#Add in the care type -- confirm that it is supposed to be year-specific
caretype <- read.dta13("y2caretype.dta", nonint.factors = TRUE) %>% 
  mutate(cid = as.character(cid))

#Remove observations that have no care type or no classroom observation
outcomes_and_obs_full_y2 <- left_join(outcomes_and_obs_y2, caretype, by = "cid") %>% 
  mutate(hasobservation = is.na(classid)) %>% 
  filter(!is.na(caretype)) %>%
  filter(!is.na(classid))

# outcomes_and_obs_full_y1 <- outcomes_and_obs %>% 
#   filter(!is.na(classid))

#Remove Y1 and Y2 data for cleanliness
outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  select(-starts_with(c("y1", "y2")))

#Remove some irrelevant variables
outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  # seems like provid is the same thing as famid in this case?
  select(-c(provid, dob, actualtype_fcc:hasobservation)) %>% 
  mutate(caretype = as.factor(caretype),
         actualtype = as.factor(actualtype))

## INSERT SOME REPLACE.NA FUNCTION HERE
```


```{r merge.obs.outcomes y2 p2}
#There are some issues with NA and NaN in the observation data that will mess up our analysis. We will replace these with the mean of the variables

replace.na <- function(var){
  ifelse(is.na(var) | is.nan(var), mean(var), var)
}
# names(outcomes_and_obs_full_y1)
# double check whether mean imputation works for factors
outcomes_and_obs_full_y2 <- outcomes_and_obs_full_y2 %>% 
  mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)

# what is o_t_sched_t supposed to be for? replacing with actualtype for now just to run analysis

# replacing all NaNs in hopes that it will fix the model matrix issue
# originally was o_c_verbal_talk:o_t_sched_t

dim(outcomes_and_obs_full_y2)
```

## Analysis

We will first try a cross-validated LASSO, which will aggressively remove variables that do little to improve the predictive accuracy of the model.  

```{r loop lasso y2, echo=TRUE, fig.height=8}
set.seed(4224)

gain_ind <- which(startsWith(colnames(outcomes_and_obs_full_y2), "gain"))

models_y2 <- list()
coefs_y2 <- list()

for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y2)[i]
  df_analysis <- outcomes_and_obs_full_y2 %>%
    filter(!is.na(outcomes_and_obs_full_y2[[name]])) %>%
    select(c(name, "o_c_verbal_Fuss/Cry (FC)":actualtype))
  print(name)
  options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  y = df_analysis[[name]]
  print(dim(x))
  x = x[, -1]
  

  # call cv.glmnet()
  model_lasso <- cv.glmnet(x = x, y = y, alpha = 1)
  plot(model_lasso)
  
  models_y2[[name]] <- model_lasso
  
  cc = coef(model_lasso, s = model_lasso$lambda.min)

  # print out the model coefficients and store in a list.
  cc = cc[cc[,1]!=0,1]
  coefs_y2[[name]] <- cc
  print(cc)
}
```

```{r y2 pulling most predictive covariates}
# loop through the names associated with each outcome -- add 1 to corresponding entry
count_coefs_y2 <- list()
for (outcome in coefs_y2) {
  for (name in names(outcome)) {
    if (name == '(Intercept)') {
      next
    }
    count_coefs_y2[[name]] <- ifelse(is.null(count_coefs_y2[[name]]), 1, 
                                     count_coefs_y2[[name]] + 1)
  }
}
```



```{r loop rf_test y2, echo=TRUE, fig.height=8}
# had to use 0 for this replace.na function? not sure what this entails...
replace.na <- function(var){
  ifelse(is.na(var) | is.nan(var), 0, var)
}

for (i in gain_ind) {
  name <- names(outcomes_and_obs_full_y1)[i]
  df_analysis <- outcomes_and_obs_full_y1 %>%
    filter(!is.na(outcomes_and_obs_full_y1[[name]])) %>%
    select(c(name, "o_c_verbal_Fuss/Cry (FC)":actualtype)) %>%
    # ask about verbal_fuss vs o_c_verbal_Talk(T) (original)
    mutate_at(vars("o_c_verbal_Fuss/Cry (FC)":actualtype), replace.na)
  print(name)
  # options(na.action="na.pass")
  x = model.matrix(as.formula(paste(name, "~ .")), data = df_analysis)
  
  # Fit the random forest model
  rf_fit <- train(as.formula(paste(name, "~ ."), #Use all variables in the prediction
                data = df_analysis, #Use the training data
                method = "ranger",
                importance = "permutation",
                num.trees = 500,
                na.action=na.pass))
                
  varImp(rf_fit) %>%
    pluck(1) %>%
    rownames_to_column("var") %>%
    ggplot(aes(x = reorder(var, Overall), y = Overall)) +
    geom_col(fill = "grey75") +
    coord_flip() +
    theme_minimal()
}
```


```{r multiple predictors, echo=TRUE, fig.height=8}
# Try a model with a bunch of predictors from Y1 Y2 -- question: what would be predicted, then?
# since it looks like the gains are different from year to year

outcomes_and_obs_full_y2
```


```{r community based, echo=TRUE, fig.height=8}
#3. Use the particular caretype from the  setting that is being observed in. (prov_type)
#Collapse CC-Community Based & CC- License Exempt
```


```{r variances and means, echo=TRUE, fig.height=8}
#4. Drop all variances and instead focus on means
```


```{r child-level covariates, echo=TRUE, fig.height=8}
#5. Incorporte child-level covariates
```


```{r age and elapsed time for assessment, echo=TRUE, fig.height=8}

#6. Age and elapsed time for assessment
